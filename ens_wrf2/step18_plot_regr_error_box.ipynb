{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read gridinfo mask\n",
      "Read regression uncertainty\n",
      "046grids\n",
      " -- read spatial uncertainty\n",
      " -- calculate temporal mean\n",
      " -- extract unmasked values\n",
      "099grids\n",
      " -- read spatial uncertainty\n",
      " -- calculate temporal mean\n",
      " -- extract unmasked values\n",
      "393grids\n",
      " -- read spatial uncertainty\n",
      " -- calculate temporal mean\n",
      " -- extract unmasked values\n",
      "Save\n",
      "Precp'\n",
      "Precp_2'\n",
      "Tmean\n",
      "Tmean_2\n",
      "Trange\n",
      "Trange_2\n",
      "Plot\n",
      "Precp'\n",
      "Precp_2'\n",
      "Tmean\n",
      "Tmean_2\n",
      "Trange\n",
      "Trange_2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "def read_regr(file):\n",
    "\n",
    "    file = os.path.join(file)\n",
    "    f=xr.open_dataset(file)\n",
    "    time = f['time'].values[:]        \n",
    "    pcp_error = f.variables['pcp_error'].values[:]\n",
    "    pcp_error_2 = f.variables['pcp_error_2'].values[:]\n",
    "    tmean_error = f.variables['tmean_error'].values[:]\n",
    "    tmean_error_2 = f.variables['tmean_error_2'].values[:]\n",
    "    trange_error = f.variables['trange_error'].values[:]\n",
    "    trange_error_2 = f.variables['trange_error_2'].values[:]\n",
    "\n",
    "    time = pd.DatetimeIndex(time)\n",
    "        \n",
    "    return time, pcp_error, pcp_error_2, tmean_error, tmean_error_2, trange_error, trange_error_2\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir='/glade/u/home/hongli/scratch/2019_10_01gssha/ens_forc_wrf2'\n",
    "grid_file = os.path.join(root_dir,'GMET_tpl/inputs/gridinfo.nc')\n",
    "# grid_file = '/glade/u/home/hongli/scratch/2019_10_01gssha/ens_forc_wrf2/GMET_tpl/inputs/gridinfo.nc'\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform')\n",
    "# result_dir = os.path.join(root_dir,'test_uniform_v1')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "\n",
    "scenarios_ids = np.arange(0,3)  \n",
    "intervals =  np.arange(3,0,-1) \n",
    "scenario_num = len(scenarios_ids)\n",
    "\n",
    "subforlder = 'outputs'\n",
    "regr_filename = 'regress_ts.nc'\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "plot_date_start = '2017-12-02'\n",
    "plot_date_end = '2018-04-07'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "dpi_value = 150\n",
    "output_dir=os.path.join(root_dir, 'scripts/step18_plot_regr_error_box')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_filename = 'step18_plot_regr_error_box.png'\n",
    "# output_filename = 'step18_plot_regr_error_box_v1.png'\n",
    "    \n",
    "#======================================================================================================\n",
    "print('Read gridinfo mask')\n",
    "# get xy mask from gridinfo.nc\n",
    "f = xr.open_dataset(grid_file)\n",
    "mask_xy = f['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "mask_xy = (mask_xy!=0)\n",
    "\n",
    "#======================================================================================================\n",
    "# read scenario regression results and save to dictionary\n",
    "print('Read regression uncertainty')\n",
    "\n",
    "for k in range(scenario_num):\n",
    "# for k in range(1):\n",
    "\n",
    "    test_folder = test_folders[scenarios_ids[k]]\n",
    "    \n",
    "    print(test_folder)\n",
    "    test_dir = os.path.join(result_dir, test_folder)\n",
    "    fig_title= test_folder\n",
    "\n",
    "    print(' -- read spatial uncertainty')\n",
    "    # read regression uncertainty    \n",
    "    output_file = os.path.join(test_dir,subforlder, regr_filename)\n",
    "    time_regr, pcp_error, pcp_error_2, tmean_error, tmean_error_2, trange_error, trange_error_2 = read_regr(output_file)\n",
    "    \n",
    "    # define plot mask for nldas ensemble\n",
    "    mask_ens_t = (time_regr>=plot_date_start_obj) & (time_regr<=plot_date_end_obj)\n",
    "    \n",
    "    print(' -- calculate temporal mean')\n",
    "    # caluclate time series mean(ny,nx)\n",
    "    pcp_error_mean = np.nanmean(pcp_error[mask_ens_t,:,:],axis=0)     \n",
    "    pcp_error_2_mean = np.nanmean(pcp_error_2[mask_ens_t,:,:],axis=0)     \n",
    "    tmean_error_mean = np.nanmean(tmean_error[mask_ens_t,:,:],axis=0)\n",
    "    tmean_error_2_mean = np.nanmean(tmean_error_2[mask_ens_t,:,:],axis=0)\n",
    "    trange_error_mean = np.nanmean(trange_error[mask_ens_t,:,:],axis=0)\n",
    "    trange_error_2_mean = np.nanmean(trange_error_2[mask_ens_t,:,:],axis=0)\n",
    "    \n",
    "    print(' -- extract unmasked values')\n",
    "    # extract unmasked values\n",
    "    pcp_error_mean=pcp_error_mean[mask_xy]    \n",
    "    pcp_error_2_mean=pcp_error_2_mean[mask_xy]    \n",
    "    tmean_error_mean=tmean_error_mean[mask_xy] \n",
    "    tmean_error_2_mean=tmean_error_2_mean[mask_xy] \n",
    "    trange_error_mean=trange_error_mean[mask_xy] \n",
    "    trange_error_2_mean=trange_error_2_mean[mask_xy] \n",
    "    \n",
    "    # save to array\n",
    "    if k == 0:\n",
    "        grid_num = len(pcp_error_mean)\n",
    "        pcp_error_mean_arr = np.zeros((grid_num,scenario_num)) \n",
    "        pcp_error_2_mean_arr = np.zeros((grid_num,scenario_num))\n",
    "        tmean_error_mean_arr = np.zeros((grid_num,scenario_num)) \n",
    "        tmean_error_2_mean_arr = np.zeros((grid_num,scenario_num)) \n",
    "        trange_error_mean_arr = np.zeros((grid_num,scenario_num))\n",
    "        trange_error_2_mean_arr = np.zeros((grid_num,scenario_num))\n",
    "    \n",
    "    pcp_error_mean_arr[:,k] = pcp_error_mean\n",
    "    pcp_error_2_mean_arr[:,k] = pcp_error_2_mean\n",
    "    tmean_error_mean_arr[:,k] = tmean_error_mean \n",
    "    tmean_error_2_mean_arr[:,k] = tmean_error_2_mean \n",
    "    trange_error_mean_arr[:,k] = trange_error_mean\n",
    "    trange_error_2_mean_arr[:,k] = trange_error_2_mean\n",
    "    \n",
    "    del pcp_error_mean, pcp_error_2_mean, tmean_error_mean, trange_error_mean, tmean_error_2_mean, trange_error_2_mean\n",
    "    del pcp_error, pcp_error_2, tmean_error, trange_error , tmean_error_2, trange_error_2  \n",
    "\n",
    "#======================================================================================================    \n",
    "# save\n",
    "print('Save')\n",
    "var_list = [\"Precp'\", \"Precp_2'\", 'Tmean', 'Tmean_2', 'Trange', 'Trange_2']\n",
    "\n",
    "ncol = 2\n",
    "nrow = int(np.ceil(len(var_list)/ncol)) \n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        kk=i*ncol+j\n",
    "        print(var_list[kk])\n",
    "        \n",
    "        # select data for each subplot\n",
    "        if kk == 0:\n",
    "            data=pcp_error_mean_arr\n",
    "        elif kk == 1:\n",
    "            data=pcp_error_2_mean_arr\n",
    "        elif kk == 2:\n",
    "            data=tmean_error_mean_arr\n",
    "        elif kk == 3:\n",
    "            data=tmean_error_2_mean_arr\n",
    "        elif kk == 4:\n",
    "            data=trange_error_mean_arr\n",
    "        elif kk == 5:\n",
    "            data=trange_error_2_mean_arr\n",
    "            \n",
    "        # save time-series mean uncertainty of all valid grids and all scenarios (once for all)\n",
    "        output_filename_txt = var_list[kk]+'_regr_unc.txt'\n",
    "        np.savetxt(os.path.join(output_dir, output_filename_txt), data, delimiter=',',\n",
    "                    fmt='%f',header='Col is sample scenario. Row is the time-series mean of regr unc in flatten valid grids. The last col is for stn_regr.')\n",
    "\n",
    "#======================================================================================================    \n",
    "# plot \n",
    "print('Plot')\n",
    "var_list = [\"Precp'\", \"Precp_2'\", 'Tmean', 'Tmean_2', 'Trange', 'Trange_2']\n",
    "\n",
    "ncol = 2 \n",
    "nrow = int(np.ceil(len(var_list)/ncol)) \n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(3*ncol,3*0.6*nrow))\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        \n",
    "        kk=i*ncol+j\n",
    "        print(var_list[kk])\n",
    "\n",
    "        # load time-series mean of uncertainty \n",
    "        output_filename_txt = var_list[kk]+'_regr_unc.txt'\n",
    "        data = np.loadtxt(os.path.join(output_dir, output_filename_txt), delimiter=',', skiprows=1)\n",
    "\n",
    "        # boxplot\n",
    "        # reference: https://matplotlib.org/3.1.1/gallery/statistics/boxplot_demo.html\n",
    "        bp = ax[i,j].boxplot(data, sym='o')#, labels=labels)\n",
    "        plt.setp(bp['boxes'], color='black')\n",
    "        plt.setp(bp['whiskers'], color='black')\n",
    "        plt.setp(bp['fliers'], color='red', marker='o',markersize=1.2)\n",
    "\n",
    "        # Add a horizontal grid to the plot, but make it very light in color\n",
    "        # so we can use it for reading data values but not be distracting\n",
    "        ax[i,j].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
    "        ax[i,j].set_axisbelow(True)\n",
    "\n",
    "        # Due to the Y-axis scale being different across samples, it can be\n",
    "        # hard to compare differences in medians across the samples. Add upper\n",
    "        # X-axis tick labels with the sample medians to aid in comparison\n",
    "        # (just use two decimal places of precision)\n",
    "        pos = np.arange(scenario_num+1) \n",
    "        medians = [(bp['medians'][k]).get_ydata()[0] for k in range(scenario_num)]\n",
    "        upper_labels = [str(np.round(s, 2)) for s in medians]\n",
    "        for tick, label in zip(range(scenario_num), ax[i,j].get_xticklabels()):\n",
    "            k = tick % 2\n",
    "            ax[i,j].text(pos[tick]+1.2, 0.9, upper_labels[tick],\n",
    "                     transform=ax[i,j].get_xaxis_transform(),\n",
    "                     horizontalalignment='center', size='xx-small',\n",
    "                     fontstyle='italic', color='b') #pos[tick], 1.02\n",
    "\n",
    "        # set y-axis label\n",
    "        y_lable = 'Regression uncertainty'\n",
    "        ax[i,j].set_ylabel(y_lable, fontsize='xx-small')\n",
    "        if i == nrow-1:\n",
    "            ax[i,j].set_xlabel('Number of sampled grids', fontsize='xx-small')\n",
    "\n",
    "#         x_ticks = [str(x) for x in range(1,10)]\n",
    "#         x_ticks.append('stn_regr')\n",
    "        x_ticks=[x.replace('grids','') for x in test_folders]\n",
    "        ax[i,j].set_xticklabels(x_ticks)\n",
    "        ax[i,j].tick_params(axis='both', direction='out',labelsize = 'xx-small',\n",
    "                            length=1.5, width=0.5, pad=1.5)       \n",
    "        # title\n",
    "        alpha = chr(ord('a') + kk)\n",
    "        ax[i,j].set_title('('+alpha+') '+var_list[kk], pad=4, fontsize='xx-small', fontweight='semibold') #pad=9\n",
    "\n",
    "# save plot\n",
    "fig.tight_layout(pad=1, h_pad=0.8)\n",
    "fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value, bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close(fig)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['046grids', '099grids', '393grids']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8064803139665934, 0.8240288874999745)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,j=392,0\n",
    "trange_error_mean_arr[i,j],trange_error_2_mean_arr[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.8343549 , 0.72911894, 0.51133275]),\n",
       " array([0.85072415, 0.75279393, 0.54295079]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmedian(trange_error_mean_arr,axis=0),np.nanmedian(trange_error_2_mean_arr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trange_error_mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
