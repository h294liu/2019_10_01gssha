{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index interval = 1, choice num = 252\n",
      "index interval = 2, choice num = 94\n",
      "index interval = 3, choice num = 46\n",
      "plot distribution\n",
      "46 Grids\n",
      "94 Grids\n",
      "252 Grids\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "# import conda\n",
    "# conda_file_dir = conda.__file__\n",
    "# conda_dir = conda_file_dir.split('lib')[0]\n",
    "# proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "# os.environ[\"PROJ_LIB\"] = proj_lib\n",
    "# reference :http://jtdz-solenoids.com/stackoverflow_/questions/54201946/how-can-i-avoid-proj-lib-error-in-importing-basemap\n",
    "os.environ[\"PROJ_LIB\"] = '/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/share/proj'\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from itertools import chain\n",
    "from osgeo import gdal\n",
    "from pyproj import Proj\n",
    "\n",
    "def plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,nx,ny,lat_0,lon_0):\n",
    "\n",
    "#     m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='cyl', ax=ax)   \n",
    "    m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='tmerc', ax=ax,lat_0=lat_0,lon_0=lon_0)\n",
    "    m.drawmapboundary(color='k', linewidth=1.)\n",
    "   \n",
    "    # lat and lon with lables\n",
    "    m.drawparallels(np.arange(np.floor(llcrnrlat),np.ceil(urcrnrlat),0.2),labels=[True,False,False,False],dashes=[1,1], fontsize='small') # Draw parallels (latitude lines) for values (in degrees).\n",
    "    m.drawmeridians(np.arange(np.floor(llcrnrlon),np.ceil(urcrnrlon),0.2),labels=[False,False,False,True],dashes=[1,1], fontsize='small') # Draw meridians (longitude lines). Label [left, right, top, bottom]\n",
    "\n",
    "    # draw a shaded-relief image\n",
    "    m.shadedrelief(scale=0.5)\n",
    "    \n",
    "    # lats and longs are returned as a dictionary\n",
    "    lats = m.drawparallels(np.reshape(np.linspace(llcrnrlat,urcrnrlat,ny+1),(ny+1,)),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "    lons = m.drawmeridians(np.reshape(np.linspace(llcrnrlon,urcrnrlon,nx+1),(nx+1,)),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "\n",
    "    lat_lines = chain(*(tup[1][0] for tup in lats.items()))\n",
    "    lon_lines = chain(*(tup[1][0] for tup in lons.items()))\n",
    "    all_lines = chain(lat_lines, lon_lines)\n",
    "    \n",
    "    # cycle through these lines and set the desired style\n",
    "    for line in all_lines:\n",
    "        line.set(linestyle='-', alpha=0.3, color='grey')\n",
    "\n",
    "    m.drawstates(linewidth=0.5, linestyle='solid', color='k')\n",
    "    return m\n",
    "\n",
    "# ===============================================================================\n",
    "root_dir='/glade/u/home/hongli/scratch/2019_10_01gssha/ens_forc_wrf2'\n",
    "grid_info_file = os.path.join(root_dir, 'dem/step4_create_gridinfo/gridinfo.nc')\n",
    "\n",
    "asc_dir = '/glade/u/home/hongli/scratch/2019_10_01gssha/model/270m_Forward_Jan01_2018-Apr15_2018_WestWRF/input/hmet_ascii_data_1day_lead'\n",
    "asc_files = [f for f in os.listdir(asc_dir) if '.asc' in f]\n",
    "asc_files = sorted(asc_files)\n",
    "\n",
    "outfolder = 'scripts/step4_sample_stnlist_perturb'\n",
    "if os.path.exists(os.path.join(root_dir, outfolder)):\n",
    "    shutil.rmtree(os.path.join(root_dir, outfolder))\n",
    "os.makedirs(os.path.join(root_dir, outfolder))\n",
    "ofile_name_base = 'stnlist'\n",
    "dpi_value = 100\n",
    "\n",
    "np.random.seed(seed=123455)\n",
    "\n",
    "# ==========================================================================================\n",
    "# read NLDAS grid info\n",
    "f = xr.open_dataset(os.path.join(root_dir,grid_info_file))\n",
    "mask = f['mask'].values[:] # 1 is valid. 0 is invalid. \n",
    "latitude = f['latitude'].values[:] \n",
    "longitude = f['longitude'].values[:] \n",
    "elev = f['elev'].values[:] \n",
    "gradient_n_s = f['gradient_n_s'].values[:] \n",
    "gradient_w_e = f['gradient_w_e'].values[:] \n",
    "\n",
    "(ny,nx)=np.shape(mask)\n",
    "(y_ids,x_ids)=np.where(mask==1)\n",
    "total_stn_num = len(y_ids)\n",
    "\n",
    "# ==========================================================================================\n",
    "# sampled grid interval\n",
    "index_intervals=[1,2,3] #1, 1/4, 1/9.  \n",
    "\n",
    "sample_num_previous = 0\n",
    "for index_interval in index_intervals:    \n",
    "    \n",
    "    # uniform sample\n",
    "    sample_indexes = np.where((y_ids%index_interval==0) & (x_ids%index_interval==0))[0]\n",
    "    sample_num = len(sample_indexes)\n",
    "    rnds=np.random.randint(low=0, high=8+1, size=np.shape(sample_indexes))\n",
    "    record = []\n",
    "    \n",
    "    # perturb in eight directions\n",
    "    if sample_num!=sample_num_previous:\n",
    "\n",
    "        for i in range(sample_num):\n",
    "            choice_index = sample_indexes[i]\n",
    "            rnd = rnds[i]\n",
    "            y_id_origin = y_ids[choice_index]\n",
    "            x_id_origin = x_ids[choice_index]\n",
    "                 \n",
    "            if rnd in [1,2,8]:\n",
    "                y_id=y_id_origin+1    \n",
    "            elif rnd in [4,5,6]:\n",
    "                y_id=y_id_origin-1\n",
    "            else:\n",
    "                y_id=y_id_origin\n",
    "            if y_id<0 or y_id>=ny or mask[y_id,x_id_origin]!=1:\n",
    "                y_id=y_id_origin\n",
    "                           \n",
    "            if rnd in [2,3,4]:\n",
    "                x_id=x_id_origin+1\n",
    "            elif rnd in [6,7,8]:\n",
    "                x_id=x_id_origin-1  \n",
    "            else:\n",
    "                x_id=x_id_origin\n",
    "            if x_id<0 or x_id>=nx or mask[y_id,x_id]!=1:\n",
    "                x_id=x_id_origin\n",
    "            \n",
    "            if [y_id,x_id] not in record:\n",
    "                record.append([y_id,x_id])\n",
    "    \n",
    "    # record the perturbed samples\n",
    "    sample_num = len(record)        \n",
    "#     ofile = ofile_name_base +'_'+str('%03d' %(sample_num))+'grids'+ '_interval'+str(index_interval)+'.txt'\n",
    "    ofile = ofile_name_base +'_'+str('%03d' %(sample_num))+'grids'+'.txt'\n",
    "    f_out = open(os.path.join(root_dir, outfolder, ofile), 'w') \n",
    "    f_out.write('NSITES\\t'+str(sample_num)+'\\n') # total number line\n",
    "    f_out.write('STA_ID LAT LON ELEV SLP_N SLP_E STA_NAME\\n') # title line\n",
    "    \n",
    "    print('index interval = '+str(index_interval)+', choice num = '+str(sample_num))\n",
    "\n",
    "    \n",
    "    for i in range(sample_num):\n",
    "        y_id = record[i][0]\n",
    "        x_id = record[i][1]\n",
    "        sta_id = 'Row'+str('%03d' %(y_id))+'Col'+str('%03d' %(x_id))\n",
    "        lat_i=latitude[y_id,x_id]\n",
    "        lon_i=longitude[y_id,x_id]\n",
    "        ele_i=elev[y_id,x_id]\n",
    "        gradient_n_s_i=gradient_n_s[y_id,x_id]\n",
    "        gradient_w_e_i=gradient_w_e[y_id,x_id]\n",
    "        stn_name = '\"'+sta_id+'\"'\n",
    "        f_out.write('%s, %f, %f, %f, %f, %f, %s\\n' \\\n",
    "                    % (sta_id, lat_i, lon_i, ele_i, gradient_n_s_i, gradient_w_e_i, stn_name)) \n",
    "\n",
    "    f_out.close()\n",
    "    sample_num_previous=sample_num        \n",
    "\n",
    "# ==========================================================================================\n",
    "print('plot distribution')\n",
    "# lat/lon bounds and central lat/lon\n",
    "with open(os.path.join(asc_dir, asc_files[0]), 'r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        line = line.strip()        \n",
    "        if line:\n",
    "            if ('ncols' in line):\n",
    "                ncols = int(line.split()[1])\n",
    "                nx = ncols\n",
    "            elif ('nrows' in line):\n",
    "                nrows = int(line.split()[1])\n",
    "                ny = nrows\n",
    "            elif ('xllcorner' in line):\n",
    "                xllcorner = float(line.split()[1])\n",
    "            elif ('yllcorner' in line):\n",
    "                yllcorner = float(line.split()[1])\n",
    "            elif ('cellsize' in line):\n",
    "                cellsize = float(line.split()[1])\n",
    "\n",
    "p = Proj(proj='utm',zone=10,ellps='WGS84', preserve_units=False)\n",
    "start_lon, start_lat = p(xllcorner, yllcorner, inverse=True)\n",
    "end_lon, end_lat = p(xllcorner+cellsize*nx, yllcorner+cellsize*ny, inverse=True)\n",
    "\n",
    "lat_0=0.5*(start_lat+end_lat)\n",
    "lon_0=0.5*(start_lon+end_lon)\n",
    "\n",
    "# plot\n",
    "stnlist_files = [f for f in os.listdir(os.path.join(root_dir, outfolder)) if ofile_name_base in f]\n",
    "stnlist_files = sorted(stnlist_files)\n",
    "# data = np.loadtxt(os.path.join(root_dir,outfolder,stnlist_files[-1]), skiprows=1, delimiter=',', dtype='str')\n",
    "# total_stn_num = len(data)\n",
    "total_stn_num = 393\n",
    "\n",
    "nrow = 1 #1\n",
    "ncol = 3 #len(stnlist_files)\n",
    "fig, ax = plt.subplots(nrow, ncol)\n",
    "fig.set_figwidth(3.5*ncol) \n",
    "fig.set_figheight(4*nrow)\n",
    "\n",
    "for j in range(ncol):\n",
    "\n",
    "    k = j            \n",
    "    if k<len(stnlist_files):  \n",
    "\n",
    "        # read sampled stnlist.txt\n",
    "        stnlist_file = os.path.join(root_dir, outfolder, stnlist_files[k])\n",
    "        data = np.loadtxt(stnlist_file, skiprows=2, delimiter=',', dtype='str') #STA_ID[0], LAT[1], LON[2], ELEV[3], SLP_N[4], SLP_E[5], STA_NAME[6]\n",
    "        stn_num = len(data)\n",
    "        stn_lons = [float(data[i][2]) for i in range(stn_num)]\n",
    "        stn_lats = [float(data[i][1]) for i in range(stn_num)]\n",
    "        print(str(stn_num) +' Grids')\n",
    "\n",
    "        m = plot_basemap(llcrnrlon=start_lon,llcrnrlat=start_lat,\n",
    "                         urcrnrlon=end_lon,urcrnrlat=end_lat, ax=ax[j],\n",
    "                         nx=nx,ny=ny,lat_0=lat_0,lon_0=lon_0) # plot Basemap                           \n",
    "\n",
    "        x, y = m(stn_lons,stn_lats) # convert the lat/lon values to x/y projections.\n",
    "        m.plot(x, y, 'bs', markersize=2) # plot sampeld grid points\n",
    "\n",
    "        # set title\n",
    "        perctl=round(stn_num/total_stn_num*100,0)\n",
    "        title_str = '('+chr(ord('a') + k) +') ' + str(stn_num)  +' Sampled Grids ('+str('%d' %(perctl))+'%)'\n",
    "        ax[j].set_title(title_str, fontsize='small', fontweight='semibold')\n",
    "\n",
    "    else: # blank axis\n",
    "        ax[j].axis('off')\n",
    "\n",
    "# save plot\n",
    "fig.tight_layout()\n",
    "ofile = 'sample_grids_dist.png'\n",
    "fig.savefig(os.path.join(root_dir, outfolder, ofile), dpi=dpi_value)\n",
    "plt.close(fig)    \n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(stnlist_file, skiprows=2, delimiter=',', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/u/home/hongli/scratch/2019_10_01gssha/ens_forc_wrf2/scripts/step4_sample_stnlist_perturb/stnlist_00011grids_interval6.txt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stnlist_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 8, 0, 7, 4, 8, 4, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd=np.random.randint(low=0, high=8, size=np.shape(choice_index))\n",
    "rnd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
