{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/xarray/core/merge.py:17: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) convert UTM projection to WGS lat/lon\n",
      "(2) get time series\n",
      "(3) write netcdf\n",
      "Temp\n",
      "Clod\n",
      "Drad\n",
      "Grad\n",
      "Pres\n",
      "RlHm\n",
      "WndS\n",
      "Prcp\n",
      "(4) write daily netcdf\n",
      "tmin\n",
      "tmax\n",
      "prcp\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Proj\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import pandas as pd \n",
    "\n",
    "root_dir = '/glade/u/home/hongli/work/russian/ens_forc_wrf2/scripts'\n",
    "asc_dir = os.path.join(root_dir, 'hmet_ascii_data_1day_lead')\n",
    "asc_files = [f for f in os.listdir(asc_dir) if '.asc' in f]\n",
    "asc_files = sorted(asc_files)\n",
    "\n",
    "outfolder = 'step1_asc_to_nc'\n",
    "if not os.path.exists(os.path.join(root_dir, outfolder)):\n",
    "    os.makedirs(os.path.join(root_dir, outfolder))\n",
    "ofile_base = 'WestWRF'\n",
    "ofile_daily_base = 'WestWRF_daily'\n",
    "\n",
    "# =========================================================================\n",
    "# convert UTM projection to WGS lat/lon\n",
    "print('(1) convert UTM projection to WGS lat/lon')\n",
    "# read a asc file\n",
    "with open(os.path.join(asc_dir, asc_files[0]), 'r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        line = line.strip()        \n",
    "        if line:\n",
    "            if ('ncols' in line):\n",
    "                ncols = int(line.split()[1])\n",
    "                nx = ncols\n",
    "            elif ('nrows' in line):\n",
    "                nrows = int(line.split()[1])\n",
    "                ny = nrows\n",
    "            elif ('xllcorner' in line):\n",
    "                xllcorner = float(line.split()[1])\n",
    "            elif ('yllcorner' in line):\n",
    "                yllcorner = float(line.split()[1])\n",
    "            elif ('cellsize' in line):\n",
    "                cellsize = float(line.split()[1])\n",
    "\n",
    "\n",
    "# convert projected coordinates to geographic coordinates\n",
    "y = np.asarray([yllcorner+cellsize*i+cellsize*0.5 for i in range(ny)]) # north, latitude \n",
    "x = np.asarray([xllcorner+cellsize*i+cellsize*0.5 for i in range(nx)]) # east, longitude\n",
    "\n",
    "y_2d = np.repeat(np.reshape(y, (ny,1)), nx, axis=1) #(ny, nx)\n",
    "x_2d = np.repeat(np.reshape(x, (1,nx)), ny, axis=0) \n",
    "\n",
    "p = Proj(proj='utm',zone=10,ellps='WGS84', preserve_units=False)\n",
    "lons, lats = p(x_2d, y_2d, inverse=True) # inverse transform\n",
    "\n",
    "# write lat/lon\n",
    "f=open(os.path.join(root_dir, outfolder,'PointXY.txt'),'w')\n",
    "f.write('FID,Latitude,Longitude,Y,X\\n')\n",
    "for i in range(ny):\n",
    "    for j in range(nx):\n",
    "        f.write('%d,%f,%f,%f,%f\\n' % (i*nx+j+1, lats[i,j], lons[i,j], y_2d[i,j], x_2d[i,j]))\n",
    "f.close()\n",
    "\n",
    "# write start_lat, end_lat, start_lon, end_lon\n",
    "start_lon, start_lat = p(xllcorner, yllcorner, inverse=True)\n",
    "end_lon, end_lat = p(xllcorner+cellsize*nx, yllcorner+cellsize*ny, inverse=True)\n",
    "\n",
    "f=open(os.path.join(root_dir, outfolder,'PointXY_Bounds.txt'),'w')\n",
    "f.write('Start_lat,End_lat,Start_lon,End_lon\\n')\n",
    "f.write('%f,%f,%f,%f\\n' % (start_lat, end_lat, start_lon, end_lon))\n",
    "\n",
    "f.write('\\n')\n",
    "f.write('Lat_width,Lon_width\\n')\n",
    "f.write('%f,%f\\n' % (end_lat-start_lat, end_lon-start_lon))\n",
    "f.close()\n",
    "\n",
    "# =========================================================================\n",
    "# get time series\n",
    "print('(2) get time series')\n",
    "time_str = [f.split('_')[0] for f in asc_files if 'Temp' in f]\n",
    "time_str = sorted(time_str)\n",
    "times = [datetime.strptime(t_str,'%Y%m%d%H') for t_str in time_str]\n",
    "\n",
    "# =========================================================================\n",
    "# write netcdf   \n",
    "print('(3) write netcdf')\n",
    "ofile = ofile_base+'_'+time_str[0]+'_'+time_str[-1]+'.nc'\n",
    "with nc.Dataset(os.path.join(root_dir, outfolder, ofile), \"w\") as ncfile:\n",
    "\n",
    "    # create global attributes\n",
    "    ncfile.source = 'Hourly forcing from GSSHA West WRF ASCII'\n",
    "\n",
    "    # create dimensions\n",
    "    lat_dim = ncfile.createDimension('y', ny) # latitude axis\n",
    "    lon_dim = ncfile.createDimension('x', nx) # longitude axis\n",
    "    time_dim = ncfile.createDimension('time', None) # unlimited axis\n",
    "\n",
    "    # =========================================================================\n",
    "    # create variables for lat/lon coordinates and time \n",
    "    lat = ncfile.createVariable('lat', np.float32, ('y','x'))\n",
    "    lat.units = 'degrees_north'\n",
    "    lat.long_name = 'latitude'\n",
    "\n",
    "    lon = ncfile.createVariable('lon', np.float32, ('y','x'))\n",
    "    lon.units = 'degrees_east'\n",
    "    lon.long_name = 'longitude'\n",
    "\n",
    "    time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "    time.units = 'hours since 1980-01-01 00:00:00'\n",
    "    time.long_name = 'time'\n",
    "\n",
    "    # assign values for variables ([:] is necessary)\n",
    "    lat[:] = lats\n",
    "    lon[:] = lons\n",
    "    time[:] = nc.date2num(times, ncfile.variables['time'].units)\n",
    "\n",
    "    # =========================================================================\n",
    "    # create forcing variables [loop variables and loop times]\n",
    "    vars_short = ['Temp','Clod','Drad','Grad','Pres','RlHm','WndS','Prcp']\n",
    "    vars_long = ['Temperature', 'Cloud Cover', 'Direct Radiation', \n",
    "                 'Global Radiation', 'Pressure', 'Relative Humidity', 'Wind Speed', 'Precipitation']\n",
    "    units = ['Fahrenheit', 'Percent', 'Watt hour per meter squared',\n",
    "             'Watt hour per meter squared', 'Inches Hg', 'Percent', 'Knots', 'mm/hr']\n",
    "\n",
    "    for i, var in enumerate(vars_short):\n",
    "        print(var)\n",
    "\n",
    "        # create\n",
    "        var_i = ncfile.createVariable(var,np.float64,('time','y','x')) # note: unlimited dimension is leftmost\n",
    "        var_i.long_name = vars_long[i]\n",
    "        var_i.units = units[i] \n",
    "\n",
    "        # write\n",
    "        var_files = [f for f in asc_files if var in f]\n",
    "        var_files = sorted(var_files)\n",
    "        for var_file in var_files:\n",
    "#             print(var_file)\n",
    "            time_index = time_str.index(var_file.split('_')[0])\n",
    "            data = np.loadtxt(os.path.join(asc_dir, var_file), skiprows=5, dtype=float)\n",
    "            var_i[time_index,:,:] = np.flipud(data)\n",
    "# ==========================================================================================================\n",
    "# Convert hourly WRF forcing to daily in order to run GMET (only P and T)\n",
    "print('(4) write daily netcdf')\n",
    "time_format_daily = '%Y%m%d'\n",
    "\n",
    "ofile = ofile_base+'_'+time_str[0]+'_'+time_str[-1]+'.nc'\n",
    "f_wrf = xr.open_dataset(os.path.join(root_dir, outfolder, ofile))\n",
    "time = pd.to_datetime(f_wrf['time'].values[:]).strftime(time_format_daily) #yyyy-mm-dd\n",
    "prcp_hour = f_wrf['Prcp'].values[:] # (time, lat, lon). unit: mm/hr\n",
    "temp_hour_F = f_wrf['Temp'].values[:] # (time, lat, lon). unit: F\n",
    "\n",
    "# use mask when converting from F to C\n",
    "(nt_hour,ny,nx)=np.shape(temp_hour_F)\n",
    "mask = (np.ones((ny,nx))!=1)\n",
    "mask[0:4,0]=True\n",
    "mask[0,-1]=True\n",
    "mask[-2,0:2]=True\n",
    "mask[-1,0:10]=True\n",
    "mask[-8:,-1]=True\n",
    "mask = np.flipud(mask)\n",
    "mask = np.repeat(mask[np.newaxis,:,:],nt_hour,axis=0)\n",
    "\n",
    "temp_hour_F_mask = np.ma.array(temp_hour_F, mask=mask)\n",
    "temp_hour_C_mask = np.multiply(np.subtract(temp_hour_F_mask, 32), 5.0/9.0) # F to C\n",
    "\n",
    "# daily datetime\n",
    "time_str_unique = np.unique(time)\n",
    "datetime_unique = [datetime.strptime(t, time_format_daily) for t in time_str_unique]\n",
    "date_len = len(time_str_unique)\n",
    "\n",
    "# convert hourly to daily\n",
    "[hr_len, ny, nx] = np.shape(prcp_hour)\n",
    "prcp_daily = np.zeros((date_len, ny, nx))\n",
    "tmin_daily = np.zeros((date_len, ny, nx))\n",
    "tmax_daily = np.zeros((date_len, ny, nx))\n",
    "\n",
    "for i, d in enumerate(time_str_unique):\n",
    "    index=[i for i in range(len(time)) if time[i]==d]\n",
    "    prcp_daily[i,:,:] = np.nansum(prcp_hour[index,:,:], axis=0)\n",
    "    tmin_daily[i,:,:] = (temp_hour_C_mask[index,:,:].min(axis=0)).filled(fill_value=0)\n",
    "    tmax_daily[i,:,:] = (temp_hour_C_mask[index,:,:].max(axis=0)).filled(fill_value=0)\n",
    "\n",
    "# save daily output\n",
    "ofile_daily = ofile_daily_base+'_'+time_str_unique[0]+'_'+time_str_unique[-1]+'.nc'\n",
    "\n",
    "with nc.Dataset(os.path.join(root_dir, outfolder, ofile)) as src:\n",
    "    with nc.Dataset(os.path.join(root_dir, outfolder, ofile_daily), \"w\") as dst:\n",
    "\n",
    "        # create global attributes\n",
    "        dst.description = 'Daily WRF derived from ERDC hourly ascii forcing.'\n",
    "\n",
    "        # copy dimensions\n",
    "        for name, dimension in src.dimensions.items():\n",
    "             dst.createDimension(\n",
    "                name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "\n",
    "        # copy variable attributes all at once via dictionary (for the included variables)\n",
    "        include = ['lat', 'lon', 'time']\n",
    "        for name, variable in src.variables.items():\n",
    "            if name in include:\n",
    "                x = dst.createVariable(name, variable.datatype, variable.dimensions)               \n",
    "                dst[name].setncatts(src[name].__dict__)\n",
    "                if name!='time':\n",
    "                    dst[name][:]=src[name][:]                \n",
    "\n",
    "        # assign values for variables ([:] is necessary)\n",
    "        dst.variables['time'][:] = nc.date2num(datetime_unique, dst.variables['time'].units)\n",
    "\n",
    "        # create Prcp, Tmin, and Tmax variables \n",
    "        vars_short = ['tmin','tmax','prcp']\n",
    "        vars_long = ['Minimum daily air temperature', 'Maximum daily air temperature', 'Total daily precipitation']\n",
    "        units = ['degC', 'degC', 'mm/day']\n",
    "\n",
    "        for i, var in enumerate(vars_short):\n",
    "            print(var)\n",
    "\n",
    "            # create\n",
    "            var_i = dst.createVariable(var,np.float64,('time','y','x')) # note: unlimited dimension is leftmost\n",
    "            var_i.long_name = vars_long[i]\n",
    "            var_i.units = units[i] \n",
    "\n",
    "        dst.variables['tmax'][:] = tmax_daily\n",
    "        dst.variables['tmin'][:] = tmin_daily\n",
    "        dst.variables['prcp'][:] = prcp_daily \n",
    "        \n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENTER]",
   "language": "python",
   "name": "conda-env-ENTER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
